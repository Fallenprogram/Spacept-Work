{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PCA Test Normalisation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMJjUbR/7telFe2/mv5XPg7"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":167,"output_embedded_package_id":"1OoAq5A6PqlQvtfpx8UIG5DWYy4MjmQ6J"},"id":"g325Sb431nb_","executionInfo":{"status":"ok","timestamp":1606743546337,"user_tz":0,"elapsed":45032,"user":{"displayName":"Jonathan Chee Xian Kuan","photoUrl":"","userId":"09977317437316533884"}},"outputId":"78b5ee80-e2d1-4738-dd3e-e994eda51017"},"source":["from google.colab import files\n","files.upload()\n","files.upload()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"lAGgPr-UUj1P"},"source":["import cv2\n","from collections import Counter\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.cluster import KMeans\n","from sklearn.decomposition import PCA\n","from sklearn.metrics import pairwise_distances_argmin\n","from sklearn.utils import shuffle\n","from time import time\n","from PIL import Image\n","\n","\n","\"\"\"HELPER FUNCTIONS\"\"\"\n","\n","# Perform quantization - called by runner()\n","def quantize(img=\"A.PNG\",\n","             img_quant_kmean=\"A_kmean.PNG\", img_quant_random=\"A_random.PNG\"):\n","    \"\"\"\n","    Normalize the R/G/B histograms of B separately to match A\n","    :param img: The filepath (string) to the original image, with image file extension\n","    :param img_quant_kmean: The filepath (string) to the image after K-means quantization, with image file extension\n","    :param img_quant_random: The filepath (string) to the image after random quantization, with image file extension\n","    :returns: Nothing, but the image files are just saved in the respective filepaths\n","    \"\"\"\n","\n","    n_colors = 64\n","\n","    # Load the photo\n","    oilspill = Image.open(img)\n","\n","    # Convert to floats instead of the default 8 bits integer coding. Dividing by\n","    # 255 is important so that plt.imshow behaves works well on float data (need to\n","    # be in the range [0-1])\n","    oilspill = np.array(oilspill, dtype=np.float64) / 255\n","\n","    # Load Image and transform to a 2D numpy array.\n","    w, h, d = original_shape = tuple(oilspill.shape)\n","    image_array = np.reshape(oilspill, (w * h, d))\n","\n","    # print(\"Fitting model on a small sub-sample of the data\")\n","    # t0 = time()\n","    image_array_sample = shuffle(image_array, random_state=0)[:1000]\n","    kmeans = KMeans(n_clusters=n_colors, random_state=0).fit(image_array_sample)\n","    # print(\"done in %0.3fs.\" % (time() - t0))\n","\n","    # Get labels for all points\n","    # print(\"Predicting color indices on the full image (k-means)\")\n","    # t0 = time()\n","    labels = kmeans.predict(image_array)\n","    # print(\"done in %0.3fs.\" % (time() - t0))\n","\n","    codebook_random = shuffle(image_array, random_state=0)[:n_colors]\n","    # print(\"Predicting color indices on the full image (random)\")\n","    # t0 = time()\n","    labels_random = pairwise_distances_argmin(codebook_random,\n","                                              image_array,\n","                                              axis=0)\n","    # print(\"done in %0.3fs.\" % (time() - t0))\n","\n","    def recreate_image(codebook, labels, w, h):\n","        \"\"\"Recreate the (compressed) image from the code book & labels\"\"\"\n","        d = codebook.shape[1]\n","        image = np.zeros((w, h, d))\n","        label_idx = 0\n","        for i in range(w):\n","            for j in range(h):\n","                image[i][j] = codebook[labels[label_idx]]\n","                label_idx += 1\n","        return image\n","\n","    # Display all results, alongside original image\n","    # plt.figure(1)\n","    # plt.clf()\n","    # plt.axis('off')\n","    # plt.title('Original image (96,615 colors)')\n","    # plt.imshow(oilspill)\n","\n","    # plt.figure(2)\n","    # plt.clf()\n","    # plt.axis('off')\n","    # plt.title('Quantized image (64 colors, K-Means)')\n","    # plt.imshow(recreate_image(kmeans.cluster_centers_, labels, w, h))\n","\n","    img1_output = recreate_image(kmeans.cluster_centers_, labels, w, h)\n","    img2_output = recreate_image(codebook_random, labels_random, w, h)\n","\n","    # plt.figure(3)\n","    # plt.clf()\n","    # plt.axis('off')\n","    # plt.title('Quantized image (64 colors, Random)')\n","    # plt.imshow(recreate_image(codebook_random, labels_random, w, h))\n","    # plt.show()\n","\n","    kmean_output = Image.fromarray((img1_output * 255).astype(np.uint8), \"RGBA\");\n","    kmean_output.save(img_quant_kmean)\n","    random_output = Image.fromarray((img2_output * 255).astype(np.uint8), \"RGBA\");\n","    random_output.save(img_quant_random)\n","\n","\n","# Split image array into R/G/B channels - called by normalize()\n","def split_into_rgb_channels(image):\n","    \"\"\"\n","    Split the target image into its red, green and blue channels.\n","\n","    :param image: The input image as an numpy array of shape (rows, columns, 3).\n","    :returns:\n","        output - three numpy arrays of shape (rows, columns) and dtype same as\n","         image, containing the corresponding channels.\n","    \"\"\"\n","    red = image[:, :, 2]\n","    green = image[:, :, 1]\n","    blue = image[:, :, 0]\n","    return red, green, blue\n","\n","\n","# Perform normalization - called by runner()\n","def normalize(before=\"A.PNG\", after=\"B.PNG\", after_norm=\"B_norm.PNG\"):\n","    \"\"\"\n","    Normalize the R/G/B histograms of B separately to match A\n","    :param before: The filepath (string) to the before image, with image file extension\n","    :param after: The filepath (string) to the after image, with image file extension\n","    :param after_norm: The filepath (string) to the after image after normalization, with image file extension\n","    :returns: Nothing, but the image files are just saved in the respective filepaths\n","    \"\"\"\n","\n","    # READ IMAGES\n","    reference2D = cv2.imread(before)  # before - by convention this is the reference\n","    source2D = cv2.imread(after)  # after\n","\n","    # Initialise a new size to standardise dimensions between the two images\n","    new_size = np.asarray(reference2D.shape)\n","    reference2D = cv2.resize(reference2D, (new_size[1], new_size[0])).astype(int)  # BUG FIX\n","    source2D = cv2.resize(source2D, (new_size[1], new_size[0])).astype(int)  # BUG FIX\n","\n","    reference2D_red, reference2D_green, reference2D_blue = split_into_rgb_channels(reference2D)\n","    source2D_red, source2D_green, source2D_blue = split_into_rgb_channels(source2D)\n","    target_red = np.zeros(source2D_red.shape).astype(int)\n","    target_green = np.zeros(source2D_green.shape).astype(int)\n","    target_blue = np.zeros(source2D_blue.shape).astype(int)\n","\n","    for reference2D, source2D, channel in zip(\n","        (reference2D_red, reference2D_green, reference2D_blue),\n","        (source2D_red, source2D_green, source2D_blue),\n","        (2, 1, 0)):\n","\n","        # For the rest of the analysis, unravel into a 1D array\n","        source = source2D.ravel()\n","        reference = reference2D.ravel()\n","\n","        # Get the set of unique pixel values and their corresponding indices and counts\n","        s_values, s_idx, s_counts = np.unique(\n","            source, return_inverse=True, return_counts=True)\n","\n","        # We can do the same with the reference (but we don't need the r_idx for this)\n","        r_values, r_counts = np.unique(reference, return_counts=True)\n","\n","        # Now we need to calculate the empirical cumulative distribution, scaled 0 to 1.\n","        # Each quantile tells us, for each unique value, what proportion of the data fall at or below that value.\n","        # - If matching by CDF:\n","        s_quantiles = np.cumsum(s_counts).astype(np.float64) / source.size\n","        r_quantiles = np.cumsum(r_counts).astype(np.float64) / reference.size\n","\n","        # To put it simply, we need to adjust source so that the blue line\n","        # matches the green line as closely as possible.\n","        # To do this, we can linearly interpolate on the arrays. This is the core concept of the algorithm.\n","        # The value of the source CDF at each unique input is mapped to the reference CDF\n","        # (It need not be an exact equality as we use linear interpolation).\n","        # The reference cdf value is then used to look up the corresponding reference value\n","        # (interpolated between values if the match isn't exact).\n","        # The interpolated values have the same shape as s_values -\n","        # the result is the new set of source values to replace the original.\n","        interp_r_values = np.interp(s_quantiles, r_quantiles, r_values)\n","\n","        # Now we can take our s_idx to recreate an array of the same size as the source but with new values\n","        # this is the \"new\" source2D aka. the \"B\" image\n","        if channel == 2:\n","            target_red = interp_r_values[s_idx].reshape((new_size[0], new_size[1]))\n","            target = target_red\n","        elif channel == 1:\n","            target_green = interp_r_values[s_idx].reshape((new_size[0], new_size[1]))\n","            target = target_green\n","        else:\n","            target_blue = interp_r_values[s_idx].reshape((new_size[0], new_size[1]))\n","            target = target_blue\n","\n","        # We can also visually assess the quality of the histogram match\n","        t_values, t_counts = np.unique(target, return_counts=True)\n","        t_quantiles = np.cumsum(t_counts).astype(np.float64) / target.size\n","\n","        # plt.plot(s_values, s_quantiles, label=\"Source\")\n","        # plt.plot(r_values, r_quantiles, label=\"Reference\")\n","        # plt.plot(t_values, t_quantiles, '--r', lw=2, label=\"Target\")\n","        # plt.title(channel)\n","        # plt.legend(loc=5)\n","        # plt.show()\n","\n","    target = cv2.merge((target_blue, target_green, target_red)).astype(int)\n","\n","    # Save normalised source2D image\n","    cv2.imwrite(after_norm, target)\n","\n","\n","# Find vector set - called by pcakmc()\n","def find_vector_set(diff_image, new_size, h):\n","    \"\"\"\n","    Using the difference image, finds the vector set x_d(y,x) and the mean vector of this set.\n","\n","    :param diff_image: Difference image X_d = |X_2 - X_1|\n","    :param new_size: Dimensions of the difference image\n","    :param h: Dimensions of sampling (square) block of neighbours to use for flattening to obtain 1d vector\n","    :returns:\n","        vector_set - A row matrix with (m×n)/(5×5) rows, where m×n is the dimension of the diff image\n","        mean_vec - The mean vector of vector_set\n","    \"\"\"\n","    i = 0\n","    j = 0\n","    vector_set = np.zeros((int(new_size[0] * new_size[1] / h**2), h**2))  # intialise vector_set\n","\n","    # Obtain h×h *non-overlapping* blocks of the difference image\n","    while i < vector_set.shape[0]:\n","        while j < new_size[1]:\n","            k = 0\n","            while k < new_size[0]:\n","                block = diff_image[k:k + h, j:j + h]  # BUG FIX 6 Nov 2020 swapped j and k\n","                feature = block.ravel()  # flatten the block to obtain a 1d vector\n","                vector_set[i, :] = feature\n","                k = k + h\n","            j = j + h\n","        i = i + 1\n","    mean_vec = np.mean(vector_set, axis=0)\n","    vector_set = vector_set - mean_vec  # mean-normalise the vector_set\n","    return vector_set, mean_vec\n","\n","\n","# Find feature vector space (FVS) - called by pcakmc()\n","def find_FVS(EVS, diff_image, mean_vec, new_size, r):\n","    \"\"\"\n","    Finds feature vector space using eigenvector space,\n","    by projecting the obtained eigenvectors onto to the difference image\n","\n","    :param EVS: Eigenvector set from applying PCA to the vector set\n","    :param diff_image: Difference image X_d = |X_2 - X_1|\n","    :param mean_vec: Mean vector of vector_set\n","    :param new_size: Dimensions of the difference image\n","    :param r: Sampling block half-length\n","    :return: FVS - Feature vector set\n","    \"\"\"\n","    i = r\n","    feature_vector_set = []\n","    while i < new_size[1] - r:\n","        j = r\n","        while j < new_size[0] - r:\n","            block = diff_image[j-r:j+r+1, i-r:i+r+1]  # BUG FIX 6 Nov 2020 swapped i and j\n","            feature = block.flatten()  # flatten the feature_vector_set into a 1D vector\n","            feature_vector_set.append(feature)\n","            j = j + 1\n","        i = i + 1\n","    FVS = np.dot(feature_vector_set, EVS)\n","    FVS = FVS - mean_vec  # mean-normalise the FVS\n","    return FVS\n","\n","\n","# Apply k-means clustering to FVS - called by pcakmc()\n","def clustering(FVS, clusters, new_size, r):\n","    \"\"\"\n","    Performs k-means clustering of the FVS to obtain two clusters.\n","    The cluster with the lowest number of pixels (since the changed component is lesser than the changed)\n","    is assigned to the least_index.\n","\n","    :param FVS: Feature vector set\n","    :param clusters: Number of clusters used\n","    :param new_size: Dimensions of the difference image\n","    :param r: Sampling block half-length\n","    :returns:\n","        least_index - Index of identified cluster with fewest pixels\n","        change_map - Final resulting image that displays detected changes\n","    \"\"\"\n","    kmeans = KMeans(clusters, verbose=0)\n","    kmeans.fit(FVS)\n","    output = kmeans.predict(FVS)\n","    count = Counter(output)\n","    least_index = min(count, key=count.get)\n","    change_map = np.reshape(output, (new_size[1] - 2*r, new_size[0] - 2*r))\n","    return least_index, change_map\n","\n","\n","# Wrapper function\n","def runner(before=\"A.PNG\", after=\"B.PNG\", diff=\"D.PNG\", change=\"C.PNG\",\n","            block_size=5, erode_size=3, PCA_dimen=None):\n","    \"\"\"\n","    Function that interfaces between the reading/saving of images and the actual PCA-KMC algorithm.\n","\n","    :param before: The filepath (string) to the before image, with image file extension\n","    :param after: The filepath (string) to the after image, with image file extension\n","    :param diff: The filepath (string) for the created diff image, with image file extension\n","    :param change: The filepath (string) for the created changemap image, with image file extension\n","    :param block_size: Block size (h×h) - must be odd and smaller than sqrt(longest dimension)\n","    :param erode_size: Erosion size to clean the change map\n","    :param PCA_dimen: Number of PCA dimensions to consider, set to None for default\n","    :returns: Nothing, but the image files are just saved in the diff and change filepaths\n","    \"\"\"\n","\n","    # Run quantization\n","    quantize(img=before,\n","             img_quant_kmean=before.replace(\"A\", \"A_kmean\"),\n","             img_quant_random=before.replace(\"A\", \"A_random\"))\n","    quantize(img=after,\n","             img_quant_kmean=after.replace(\"B\", \"B_kmean\"),\n","             img_quant_random=after.replace(\"B\", \"B_random\"))\n","\n","    # Run normalization\n","    normalize(before=before.replace(\"A\", \"A_kmean\"),\n","              after=after.replace(\"B\", \"B_kmean\"),\n","              after_norm=after.replace(\"B\", \"B_kmean_norm\"))\n","\n","    # Load images\n","    imgA = cv2.imread(before.replace(\"A\", \"A_kmean\"))  # t1\n","    imgB = cv2.imread(after.replace(\"B\", \"B_kmean_norm\"))  # t2\n","    imgD, imgC = pcakmc(imgA=imgA, imgB=imgB,\n","                        block_size=block_size, erode_size=erode_size, PCA_dimen=PCA_dimen)\n","\n","    # Save / Display the difference image\n","    # cv2.imshow(\"diff_image\", diff_image.astype(np.uint8))\n","    cv2.imwrite(diff, imgD)\n","    # cv2.waitKey(0)\n","    # cv2.destroyAllWindows()\n","\n","    # Display the cleaned change map\n","    # cv2.imshow(\"cleanChangeMap\", cleanChangeMap)\n","    cv2.imwrite(change, imgC)\n","    # cv2.waitKey(0)\n","    # cv2.destroyAllWindows()\n","\n","\n","# Actual PCA-KMC algorithm - called by runner()\n","def pcakmc(imgA, imgB, block_size, erode_size, PCA_dimen):\n","    \"\"\"\n","    The actual PCA-KMC algorithm\n","    This implementation is based on the following paper:\n","    Unsupervised Change Detection in Satellite Images Using Principal Component Analysis and k-Means Clustering\n","    (Turgay Celik, 2009)\n","    http://ieeexplore.ieee.org/abstract/document/5196726\n","\n","    :param imgA: An 3D R×C×K array, where R = # of pixel rows, C = # of pixel columns and K = # of channels\n","    :param imgB: An 3D R×C×K array, where R = # of pixel rows, C = # of pixel columns and K = # of channels\n","    :param block_size: Block size (h×h) - must be odd and smaller than sqrt(longest dimension)\n","    :param erode_size: Erosion size to clean the change map\n","    :param PCA_dimen: Number of PCA dimensions to consider, set to None for default\n","    :returns:\n","        imgD - An 3D R×C×K array corresponding to the diff image\n","        imgC - An 3D R×C×K array corresponding to the changemap image\n","    \"\"\"\n","\n","    if PCA_dimen is not None:\n","        assert PCA_dimen <= block_size ** 2\n","    assert block_size % 2 != 0\n","\n","    # Params\n","    h = block_size\n","    \"\"\"Block size (h×h) - must be odd and smaller than sqrt(longest dimension)\"\"\"\n","    r = int((h - 1) / 2)\n","    \"\"\"Block half-size\"\"\"\n","    c = erode_size\n","    \"\"\"Erosion size\"\"\"\n","\n","    # Convert to grayscale\n","    image1 = cv2.cvtColor(imgA, cv2.COLOR_BGR2GRAY)\n","    image2 = cv2.cvtColor(imgB, cv2.COLOR_BGR2GRAY)\n","\n","    # Initialise a new size to standardise dimensions between the two images\n","    new_size = np.asarray(image1.shape)\n","\n","    # Resize image into a multiple of block size h\n","    if image1.shape[0] % h != 0:\n","        new_size[0] = int(image1.shape[0] / h) * h\n","    if image1.shape[1] % h != 0:\n","        new_size[1] = int(image1.shape[1] / h) * h\n","\n","    # Obtain difference image, i.e. their absolute intensity value differences\n","    # Here the difference image will have pixel values different for the regions where change is noticed when compared\n","    # to the rest of the image.\n","    image1 = cv2.resize(image1, (new_size[1], new_size[0])).astype(int)  # BUG FIX\n","    image2 = cv2.resize(image2, (new_size[1], new_size[0])).astype(int)  # BUG FIX\n","    diff_image = abs(image1 - image2)  # The difference image X_d = |X_2 - X_1|\n","\n","    # Find mean-normalised vector set\n","    vector_set, mean_vec = find_vector_set(diff_image, new_size, h)\n","\n","    # Perform PCA to get eigenvector space (EVS)\n","    # Alternatively to obtain the eigenvector space,\n","    # w, v = np.linalg.eig(vector_set)\n","    # can also be used, where w is the eigenvalues and v is the eigen vectors.\n","    if PCA_dimen is None or PCA_dimen == h ** 2:  # i.e. no dimensionality reduction\n","        pca = PCA(n_components=h**2)\n","        pca.fit(vector_set)\n","    else:  # TODO Future dimensionality reduction goes under find_FVS\n","        pca = PCA(n_components=PCA_dimen)\n","        pca.fit_transform(vector_set)\n","        raise NotImplementedError\n","    EVS = pca.components_  # eigenvectors are already sorted in order of decreasing eigenvalues\n","    # eigenvalues = pca.explained_variance_  # unhide to get eigenvalues\n","\n","    # Find FVS and clusters\n","    FVS = find_FVS(EVS, diff_image, mean_vec, new_size, r)\n","    clusters = 2\n","    least_index, change_map = clustering(FVS, clusters, new_size, r)\n","\n","    # Set unchanged cluster pixels to black\n","    change_map[change_map == least_index] = 255\n","    change_map = change_map.astype(np.uint8)\n","\n","    # BUG FIX Patch to flip and rotate image at the end (TODO find better way of doing this)\n","    change_map = cv2.flip(change_map, 0)\n","    change_map = cv2.rotate(change_map, cv2.cv2.ROTATE_90_CLOCKWISE)\n","\n","    # Erode/clean the change map\n","    kernel = np.ones((c, c), np.uint8)\n","    cleanChangeMap = cv2.erode(change_map, kernel)\n","\n","    return diff_image, cleanChangeMap\n","\n","\n","if __name__ == \"__main__\":\n","    # Global parameters\n","    h = 5\n","    \"\"\"Block size (h×h) - must be odd and smaller than sqrt(longest dimension)\"\"\"\n","    c = 3\n","    \"\"\"Erosion size\"\"\"\n","\n","    \"\"\"\n","    README - TEST DATA REQUIREMENTS\n","    All image pairs should be located:\n","    - under a subfolder named \"test\" (or \"content\" for Colab)\n","    - under a subfolder numbered \"0\", \"1\", \"2\" onwards\n","    All image pairs should be named as:\n","    - \"A\" for before image\n","    - \"B\" for after image\n","    File extensions does not matter as long as:\n","    - A and B have the same file extensions\n","    - It is either .tif, .png, .jpg or .bmp format\n","    \"\"\"\n","\n","    runner(before=\"A.PNG\",\n","            after=\"B.PNG\",\n","            diff=\"D.PNG\",\n","            change=\"C.PNG\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ojs8rRkTEp0-"},"source":["# Confusion Matrix\n","from sklearn.metrics import confusion_matrix\n","confusion_matrix(y_true, y_pred)\n","# Accuracy\n","from sklearn.metrics import accuracy_score\n","accuracy_score(y_true, y_pred)\n","# Recall\n","from sklearn.metrics import recall_score\n","recall_score(y_true, y_pred, average=None)\n","# Precision\n","from sklearn.metrics import precision_score\n","precision_score(y_true, y_pred, average=None)"],"execution_count":null,"outputs":[]}]}